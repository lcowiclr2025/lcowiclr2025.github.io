<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="">
  <meta property="og:title" content="Learning to Contextualize Web Pages for Enhanced Decision Making by LLM Agents"/>
  <meta property="og:description" content="LCoW"/>
  <meta property="og:url" content="https://lcow.github.io/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  
  <style>
      .title-color {
          background-color: #193b91;
          text-align: center;
          padding: 20px 0; 
          margin: 0 auto; 
          width: 80%; 
      }
  </style>
  
  <meta name="twitter:title" content="Learning to Contextualize Web Pages for Enhanced Decision Making by LLM Agents">
  <meta name="twitter:description" content="B-MoCA serves as a testbed for mobile device control agents across dieverse configurations.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Web Agent, Large Language Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Learning to Contextualize Web Pages for Enhanced Decision Making by LLM Agents</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="bowe_componets/css/bootstrap.table.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-2 publication-title">Learning to Contextualize Web Pages for Enhanced Decision Making by LLM Agents</h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="http://dgjun32.github.io/" target="_blank">Dongjun Lee</a><sup>*1</sup>
              </span>
              <span class="author-block">
                <a href="" target="_blank">Juyong Lee</a><sup>*1</sup>
              </span>
              <span class="author-block">
                <a href="" target="_blank">Kyuyoung Kim</a><sup>1</sup>
              </span>
              <span class="author-block">
                <a href="" target="_blank">Jihoon Tack</a><sup>1</sup>
              </span>
              <span class="author-block">
                <a href="" target="_blank">Jinwoo Shin</a><sup>1</sup>
              </span>
              <span class="author-block">
                <a href="" target="_blank">Yee Whye Teh</a><sup>2</sup>
              </span>
              <span class="author-block">
                <a href="https://sites.google.com/view/kiminlee" target="_blank">Kimin Lee</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>KAIST,</span>
              <span class="author-block"><sup>2</sup>University of Oxford</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
              <span class="link-block">
                <a href="" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>Coming Soon!</span>
              </a>
            </span>

            <!-- Github link -->
            <span class="link-block">
              <a href="https://github.com/dgjun32/lcow_iclr25" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>
            </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Demonstrations section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <br>
      <div class="content has-text-centered">
        <div class="columns is-centered">
            <img src="./static/images/demonstrations/contextualize_demo.gif" width="1000" style='padding-left:10px;' class="interpolation-image"
              alt="Interpolate start reference image.">
        </div>
      </div>

      <p class="has-text-centered" style="font-size:15pt"><b>[Examplary web page contextualization for enhanced decision making of LLM agent.]</b></p>

    </div>
  </div>
</div>
</div>
</section>
<!-- End demonstration section -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered is-vcentered">
      <div class="column is-three-quarters">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advances in large language models (LLMs) have led to a growing interest in developing LLM-based agents for automating web tasks. 
            However, these agents often struggle with even simple tasks on real-world websites due to their limited capability to understand and process complex web page structures. 
            In this work, we introduce LCoW, a framework for Learning language models to Contextualize complex Web pages into a more comprehensible form, thereby enhancing decision making by LLM agents. 
            LCoW decouples web page understanding from decision making by training a separate contextualization module to transform complex web pages into comprehensible format, which are then utilized by the decision-making agent. 
            We demonstrate that our contextualization module effectively integrates with LLM agents of various scales to significantly enhance their decision-making capabilities in web automation tasks. 
            Notably, LCoW improves the success rates of closed-source LLMs (e.g., Gemini-1.5-flash, GPT-4o, Claude-3.5-Sonnet) by an average of 15.6%, and demonstrates a 23.7% average
            improvement in success rates for open-source LMs (e.g., Llama-3.1-8B, Llama-3.1-70B) on the WorkArena benchmark. 
            Moreover, the Gemini-1.5-flash agent with LCoW achieves state-of-the-art results on the WebShop benchmark, outperforming human.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Main section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">

      <div class="title-color">
          <h2 class="title" style="text-align: center; color: white;"> LCoW </h2>
      </div>
      
      <div style="width: 80%; margin: auto;">
        <md-block>
          <br>
          LCoW is a framework for training the module that contextualizes complicated web page, thereby enhancing the decision-making capabilities of LLM agents in web automation.
          The contextualization module transforms complex web page into a comprehensible and informative format, enabling LLM agents to make more accurate decisions for web navigation.
          Our training algorithm to train the contextualization module consists of three phases:  (i) trajectory collection, (ii) sampling contextualized observations, and (iii) updating the contextualization module. 
          For each observation from the collected trajectories, we generate multiple contextualized observations using the current contextualization module. 
          Each observation is then assigned a reward based on whether a set of LLM agents can accurately predict the correct action given the contextualized observation. 
          Finally, we select the one with the highest reward as the target and train the contextualization module to maximize the likelihood of the target given the original raw observation.
          <br><br>
        </md-block>
      </div>
    </div>
</div>
</section>
<!-- End Main section -->


<!-- Experiment section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">

      <div class="title-color">
          <h2 class="title" style="text-align: center; color: white;"> Experiments </h2>
      </div>
      <div style="width: 80%; margin: auto;">
        <md-block>
        <br>
        We investigate the efficacy of LCoW across multiple LLM agents in WebShop. 
        For all LLM agents, LCoW consistently improves both success rate and reward over iterations, surpassing self-contextualization (self-ctx) and even human expert-level success rate (59.6%) by the third iteration.
        Additionally, LCoW is also effective when combined with Llama-3.1-70B, which was not used for computing the action-matching reward (i.e., unseen) during training the contextualization module.
        <br><br>
        </md-block>
      </div>
      <div class="columns is-centered">
        <img src="./static/images/results/webshop.png" width="600" style='padding-left:10px;' class="interpolation-image"
          alt="Interpolate start reference image.">
      </div>
      
      <div style="width: 80%; margin: auto;">
        <md-block>
        <br>
        We evaluate the success rate of five LLM agents with varying scales on 165 tasks in the WorkArena benchmark, which features more realistic web environment.
        Single iteration of LCoW shows improvement of success rate over all LLMs, even generalized to Llama-3.1-70B and Llama-3.1-8B, which were not used for computing the action matching reward.
        Especially, relatively small LLM (i.e., Llama-3.1-8B) struggles to accomplish task given complicated web pages, while improves by 36% given observation contextualized by LCoW.
        <br><br>
        </md-block>
      </div>
      <div class="columns is-centered">
        <img src="./static/images/results/workarena.png" width="600" style='padding-left:10px;' class="interpolation-image"
          alt="Interpolate start reference image.">
      </div>

      <div style="width: 80%; margin: auto;">
        <md-block>
        <br>
        We analyze whether the (1) training contextualization using seed demonstration is more effective than directly training LLM agent through behavior cloning, and (2) contextualization module trained on certain types of tasks generalizes to unseen types of tasks.
        As shown in the Figure (left), directly training the Llama-3.1-8B-Instruct using seed demonstration achieves 23.6% success rate on 165 WorkArena tasks, while Llama-3.1-8B-Instruct combined with LCoW-trained contextualization module (which is trained based on same number of seed demonstrations) achieves 37.0% success rate.
        Additionally, as shown in Figure (right), contextualization module improves task success rate by approximately 6% on tasks belonging to both seen task types and unseen task types. 
        <br><br>
        </md-block>
      </div>
      <div class="columns is-centered">
        <img src="./static/images/results/bc_generalization.png" width="800" style='padding-left:10px;' class="interpolation-image"
          alt="Interpolate start reference image.">
      </div>

    </div>
</div>
</section>
<!-- End Experiment section -->


<!--BibTex citation -->

<!--End BibTex citation -->

<!-- Statcounter tracking code -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
